{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python API for iRODS\n",
    "\n",
    "**Authors**\n",
    "- Arthur Newton (SURFsara)\n",
    "- Christine Staiger (SURFsara)\n",
    "\n",
    "**License**\n",
    "Copyright 2018 SURFsara BV\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "You will learn how to perform a simple computation from data in iRODS using the python API covered in the introduction. We will keep into account that such a computation could be performed on a HPC cluster. You will:\n",
    "\n",
    "- setup the environment for computation \n",
    "- perform simple word count calculation with existing data in iRODS\n",
    "- use iRODS metadata to keep provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to iRODS\n",
    "Note this is a recap from the previous chapter.\n",
    "To connect to iRODS we will need to authenticate via a username and password (for this course username='mara' and password='NdxJvJQujF7dq5TyBms2Xp'). Passing sensitive information over internet can be insecure. Therefore, it is best practice to do this by encoding the password first.\n",
    "The module `getpass ` asks for passwords without printing the input on screen. With  encoding function we prevent that the variable contains the plain password. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "pw = getpass.getpass().encode('utf-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an iRODS session. The iRODS instance you will be connecting to is hosted at SURFsara HPC Cloud. For connecting to iRODS you will need the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname='irodscourse.irodspoc-sara.surf-hosted.nl'\n",
    "port=1247\n",
    "username='mara'\n",
    "zonename='tempZone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this information we can create a session object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irods.session import iRODSSession\n",
    "session = iRODSSession(host=hostname, port=port, user=username, password=pw.decode('utf-16'), zone=zonename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test whether we have access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "coll = session.collections.get('/tempZone/home/mara')\n",
    "print(coll.data_objects)\n",
    "print(coll.subcollections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iHome = coll.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup computation\n",
    "We will now prepare the compute workflow as it should be executed on any worker node in a cluster. We still do that in interactive mode and on the user interface node (remember it behaves as any node in the cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from helperFunctions import *\n",
    "\n",
    "print('Creating directories for analysis and results')\n",
    "dataDir = os.environ['TMPDIR']+'/wordcountData' + '<your id>'\n",
    "ensure_dir(dataDir)\n",
    "print(dataDir)\n",
    "resultsDir = os.environ['TMPDIR']+'/wordcountResults' + '<your id>'\n",
    "ensure_dir(resultsDir)\n",
    "print(resultsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the dataset\n",
    "We need to perform a query to obtain the dataset we are interested in. For this use case, we are interested a simple analysis of word frequency in Lewis Carroll books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irods.models import Collection, DataObject, CollectionMeta, DataObjectMeta\n",
    "\n",
    "print('Searching for files')\n",
    "ATTR_NAME = 'author'\n",
    "ATTR_VALUE = 'Lewis Carroll'\n",
    "\n",
    "query = session.query(Collection.name, DataObject.name)\n",
    "filteredQuery = query.filter(DataObjectMeta.name == ATTR_NAME).\\\n",
    "                          filter(DataObjectMeta.value == ATTR_VALUE)\n",
    "print filteredQuery.all()\n",
    "iPaths = iParseQuery(filteredQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading files from iRODS to scratch\n",
    "Remember from the first part of the tutorial, that for downloading data from iRODS you first have to read the data object into memory and after that write it to a file on your local filesystem. For convenience we provide a function wich does that for us for a list of data objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Downloading: ')\n",
    "print()'\\n'.join(iPaths))\n",
    "iGetList(session, iPaths, dataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute compute workflow\n",
    "With everything setup, we can finally do our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFiles = [dataDir+'/'+f for f in os.listdir(dataDir)]\n",
    "resFile = wordcount(dataFiles,resultsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results to iRODS\n",
    "After the computation has finished. We can make the upload of the results into iRODS part of our jobscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if results are actually created and ingested into iRODS\n",
    "coll = session.collections.get('/aliceZone/home/irods-user1')\n",
    "objNames = [obj.name for obj in coll.data_objects]\n",
    "f = os.path.basename(resFile)\n",
    "count = 0\n",
    "\n",
    "while f in objNames:\n",
    "    f = os.path.basename(resFile) + '_' +str(count)\n",
    "    count = count + 1\n",
    "\n",
    "#upload\n",
    "print('Upload results to: ', coll.path + '/' + f)\n",
    "session.data_objects.put(resFile, coll.path + '/' + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce some metadata for provenance\n",
    "Now that the results are stored in iRODS, we want to link our new data to the computation and old data. Here we put some generic metadata that could link the new results with the original data. This is definitely not exhaustive and a much more detailed description would be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "obj = session.data_objects.get(coll.path + '/' + f)\n",
    "for iPath in iPaths:\n",
    "    obj.metadata.add('INPUTDAT', iPath)\n",
    "\n",
    "obj.metadata.add('ISEARCH', ATTR_NAME + '==' + ATTR_VALUE)\n",
    "obj.metadata.add('ISEARCHDATE', str(datetime.date.today()))\n",
    "print('\\n'.join([item.name +' \\t'+ item.value for item in obj.metadata.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "We have performed a simple calculation with data from iRODS. This data was downloaded to our current location as this typically gives the best performance. This staging procedure could also be done well before the computation and is also typically advised as long as the size of for instance the scratch space on the HPC cluster you are working in allows the size of the dataset. In principle, a more complex computation won't differ that much from what we have done here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
